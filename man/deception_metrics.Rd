% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/deception_metrics.R
\name{deception_metrics}
\alias{deception_metrics}
\title{Calculate Comprehensive Deception Detection and SDT Metrics}
\usage{
deception_metrics(ground_truth, response, study = NULL, honest_value = NULL, 
                 deceptive_value = NULL, export_csv = FALSE, corr_table = FALSE)
}
\arguments{
\item{ground_truth}{A vector of ground truth labels. Should contain exactly 2 unique values
(excluding NA). Standard coding uses "honest" and "deceptive", but other binary
coding schemes are supported (e.g., "truth"/"lie", "0"/"1", etc.)}

\item{response}{A vector of participant responses. Should use the same coding
scheme as ground_truth}

\item{study}{An optional vector of study identifiers for grouping (default: NULL)}

\item{honest_value}{Optional: specify which value represents "honest" responses
(default: auto-detected or "honest")}

\item{deceptive_value}{Optional: specify which value represents "deceptive" responses
(default: auto-detected or "deceptive")}

\item{export_csv}{Logical. If TRUE, exports results to a CSV file with current date (default: FALSE)}

\item{corr_table}{Logical. If TRUE, creates APA-style correlation table of all metrics (default: FALSE)}
}
\value{
A data frame containing comprehensive deception detection metrics:
\describe{
  \item{study}{Study identifier (if provided)}
  \item{n_total}{Total number of observations}
  \item{n_valid}{Number of valid (non-NA) responses}
  \item{accuracy}{Proportion of correct responses}
  \item{truth_bias}{Proportion of responses coded as "honest"}
  \item{truth_accuracy}{Accuracy on trials where ground truth is "honest"}
  \item{lie_accuracy}{Accuracy on trials where ground truth is "deceptive"}
  \item{hits}{Number of correctly identified deceptive statements}
  \item{misses}{Number of deceptive statements incorrectly identified as honest}
  \item{false_alarms}{Number of honest statements incorrectly identified as deceptive}
  \item{correct_rejections}{Number of correctly identified honest statements}
  \item{hit_rate}{Proportion of deceptive statements correctly identified}
  \item{false_alarm_rate}{Proportion of honest statements incorrectly identified as deceptive}
  \item{d_prime}{Sensitivity measure (parametric)}
  \item{a_prime}{Sensitivity measure (non-parametric)}
  \item{beta}{Response bias measure (beta)}
  \item{bppd}{Response bias measure (b-double prime)}
  \item{criterion}{Response bias measure (criterion c)}
  \item{honest_value}{Value used for "honest" coding}
  \item{deceptive_value}{Value used for "deceptive" coding}
}
}
\description{
This function calculates both basic detection accuracy metrics and comprehensive
Signal Detection Theory (SDT) metrics for deception detection studies, optionally 
grouped by study. The function automatically detects unique values in your data 
and provides guidance if the standard "honest"/"deceptive" coding is not used.
}
\examples{
# Standard coding
ground_truth <- c("honest", "deceptive", "honest", "deceptive")
response <- c("honest", "honest", "honest", "deceptive")
deception_metrics(ground_truth, response)

# Alternative coding schemes
ground_truth <- c("truth", "lie", "truth", "lie")
response <- c("truth", "truth", "truth", "lie")
deception_metrics(ground_truth, response, honest_value = "truth", deceptive_value = "lie")

# Multiple studies with CSV export and correlation table
study <- c(rep("study1", 2), rep("study2", 2))
ground_truth <- c("honest", "deceptive", "honest", "deceptive")
response <- c("honest", "honest", "honest", "deceptive")
deception_metrics(ground_truth, response, study, export_csv = TRUE, corr_table = TRUE)

}